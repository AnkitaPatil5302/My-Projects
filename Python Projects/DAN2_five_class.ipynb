{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from time import strftime, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAN2Regressor(object):\n",
    "\n",
    "    def __init__(self, depth=50, bounds=(0,5000000000)):\n",
    "        self.bounds = bounds\n",
    "        self.depth = depth\n",
    "        self.lin_predictor = LinearRegression(fit_intercept=True) \n",
    "        self.coef_ = None\n",
    "        self.name = strftime('dan2model-'+ str(depth) + '-%Y-%b-%d-%H-%M-%S', gmtime())\n",
    "        #self.lin_predictions = None\n",
    "\n",
    "\n",
    "    \"\"\" Layer activation \"\"\"\n",
    "    def f(self, x):\n",
    "        \n",
    "        f = self.f_k\n",
    "        A = self.A\n",
    "        alpha = self.alpha\n",
    "        a = self.a\n",
    "        rows = f.shape[0]\n",
    "        ''' check if intercept term should be placed first'''\n",
    "        #Xn = np.hstack((a, A[0]*f, A[1]*np.cos(alpha*x), A[2]*np.sin(alpha*x)))\n",
    "        Xn = a + A[0]*f + A[1]*np.cos(alpha*x) + A[2]*np.sin(alpha*x)\n",
    "        return np.sum(Xn)\n",
    "\n",
    "\n",
    "    \"\"\" Method to get alpha column for DAN2 \"\"\"\n",
    "    def compute_alpha(self, X):\n",
    "        cols = X.shape[1]\n",
    "\n",
    "        \"\"\" Create resultant vector of ones \"\"\"\n",
    "        R = np.ones(cols)\n",
    "        #print('R', R.shape)\n",
    "\n",
    "        \"\"\" Compute dot product \"\"\"\n",
    "        X_dot_R = (1 + np.dot(X,R))\n",
    "        #print('XdR', X_dot_R.shape)\n",
    "        X_dot_R = X_dot_R.reshape((len(X),))\n",
    "        #print('XdR', X_dot_R.shape)\n",
    "\n",
    "        \"\"\" Compute X and R magnitudes \"\"\"\n",
    "        X_mag = np.sqrt(1*1 + np.sum(np.square(X), axis=1))\n",
    "        R_mag = np.sqrt(np.sum(R**2) + 1*1)\n",
    "\n",
    "        \"\"\" Compute arccosine \"\"\"\n",
    "        acos = np.arccos(X_dot_R / (X_mag * R_mag))\n",
    "        #print('acos', acos.shape)\n",
    "\n",
    "        return acos.reshape(len(acos),1) \n",
    "\n",
    "\n",
    "    \"\"\" Linear method \"\"\"\n",
    "    def lin_reg(self, X, y):\n",
    "        self.model['lr'] = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "        return self.model['lr'].predict(X), self.model['lr'].coef_[0], self.model['lr'].intercept_\n",
    "\n",
    "\n",
    "    ''' '''\n",
    "    def build_X1(self, f, alpha):\n",
    "        return np.column_stack((f, np.cos(alpha), np.sin(alpha)))\n",
    "\n",
    "\n",
    "    ''' '''\n",
    "    def build_Xn(self, f, A, alpha, mu):\n",
    "        rows = f.shape[0]\n",
    "        if A is None and mu is None:\n",
    "            X = np.hstack((f, np.cos(alpha), np.sin(alpha)))\n",
    "            A = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "\n",
    "        return np.hstack((A[0]*f, A[1]*np.cos(alpha*mu), A[2]*np.sin(alpha*mu)))\n",
    "\n",
    "\n",
    "    def logging(self, coef_):\n",
    "        if self.coef_ is None:\n",
    "            self.coef_ = coef_.reshape(1,5)\n",
    "\n",
    "        else:\n",
    "            self.coef_ = np.vstack((self.coef_ , coef_))\n",
    "\n",
    "\n",
    "    \"\"\" Fit method  \"\"\"\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Number of rows\n",
    "        m = X.shape[0]\n",
    "\n",
    "        ## Get non-linear projection of input records\n",
    "        alpha = self.compute_alpha(X)\n",
    "        \n",
    "        ## Get linear model from n input cols\n",
    "        self.lin_predictor.fit(X, y)\n",
    "        f_k = self.lin_predictor.predict(X)\n",
    "        self.lin_predictions = f_k\n",
    "        \"\"\" Start fit algorithm \"\"\"\n",
    "        i = 1\n",
    "        mu = 1\n",
    "        while (i <= self.depth):\n",
    "            if i==1:\n",
    "                Xn = self.build_X1(f_k, alpha)\n",
    "                lr = LinearRegression(fit_intercept=True).fit(Xn, y)\n",
    "                A = lr.coef_[0]\n",
    "                a = lr.intercept_\n",
    "                f_k = lr.predict(Xn)\n",
    "            else:\n",
    "                mu = self.minimize(f_k, A, a, alpha)\n",
    "                Xn = self.build_Xn(f_k, A, alpha, mu) # eventually override the build_X1 method\n",
    "                lr = LinearRegression(fit_intercept=True).fit(Xn, y)\n",
    "                A = lr.coef_[0]\n",
    "                a = lr.intercept_\n",
    "                f_k = lr.predict(Xn) \n",
    "\n",
    "            # Error metrics\n",
    "            mse = self.mse(f_k, y, m)\n",
    "            pred = np.where(f_k >= 0.5, 1, 0)\n",
    "            acc = accuracy_score(y, pred)\n",
    "            \n",
    "            # Save layer\n",
    "            coef_ = A.reshape((1,3))\n",
    "            coef_ = np.insert(coef_, 0, a)\n",
    "            coef_ = np.insert(coef_, 0, mu)\n",
    "            print(i, coef_)\n",
    "            self.logging(coef_)\n",
    "\n",
    "            # add layers\n",
    "            print('Iteration:', i, \" Mu:\", mu, \"MSE:\", mse, \"Accuracy:\", acc)\n",
    "\n",
    "            i += 1\n",
    "        return f_k\n",
    "\n",
    "    def minimize(self, f_k, A, a, alpha):\n",
    "        self.f_k = f_k\n",
    "        self.A = A\n",
    "        self.alpha = alpha\n",
    "        self.a = a\n",
    "        res = minimize_scalar(self.f, bounds=self.bounds, method='bounded')\n",
    "        return res.x\n",
    "        \n",
    "\n",
    "    def mse(self, f_k, y, m):\n",
    "        return np.sum((f_k - y)**2) / m        \n",
    "\n",
    "    def _activation_function(self, X, coef_):\n",
    "        intercept = coef_[0]\n",
    "        A = coef_[1:]\n",
    "        return safe_sparse_dot(X, A.T, dense_output=True) + intercept\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X = X_test\n",
    "        m = X.shape[0]\n",
    "        alpha = self.compute_alpha(X)\n",
    "        f_k = self.lin_predictor.predict(X)\n",
    "        i = 0\n",
    "\n",
    "        for coef_ in self.coef_:\n",
    "            mu = coef_[0]\n",
    "            if i == 0:\n",
    "                X = np.hstack((f_k, np.cos(alpha*mu), np.sin(alpha*mu)))\n",
    "                f_k = self._activation_function(X, coef_[1:])\n",
    "                f_k = f_k.reshape(m,1)\n",
    "            else:\n",
    "                X = np.hstack((prev_coef_[2]*f_k, prev_coef_[3]*np.cos(alpha*mu), prev_coef_[4]*np.sin(alpha*mu)))\n",
    "                f_k = self._activation_function(X, coef_[1:])\n",
    "                f_k = f_k.reshape(m,1)\n",
    "\n",
    "            i += 1\n",
    "            prev_coef_ = coef_\n",
    "        return f_k\n",
    "    \n",
    "    def plot_error():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import os,string,collections\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(r\"C:\\Users\\ajaym\\Downloads\\twitter-airline-sentiment\\Tweets2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id         airline  \\\n",
       "0  5.700000e+17  Virgin America   \n",
       "1  5.700000e+17  Virgin America   \n",
       "2  5.700000e+17  Virgin America   \n",
       "3  5.700000e+17  Virgin America   \n",
       "4  5.700000e+17  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = utils.TextCleaner()\n",
    "dataset['clean_text'] = tc.transform(dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = dataset['clean_text'].apply(lambda row: tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "dataset.insert(3,\"tokenized\", tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(text: str) -> float:\n",
    "    return vader.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['score'] = dataset['clean_text'].apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>[what, said]</td>\n",
       "      <td>what said</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>[plus, youve, added, commercials, to, the, experience, tacky]</td>\n",
       "      <td>plus youve added commercials to the experience tacky</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>[i, didnt, today, must, mean, i, need, to, take, another, trip]</td>\n",
       "      <td>i didnt today must mean i need to take another trip</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>[its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]</td>\n",
       "      <td>its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse</td>\n",
       "      <td>-0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>[and, its, a, really, big, bad, thing, about, it]</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>-0.5829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id         airline  \\\n",
       "0  5.700000e+17  Virgin America   \n",
       "1  5.700000e+17  Virgin America   \n",
       "2  5.700000e+17  Virgin America   \n",
       "3  5.700000e+17  Virgin America   \n",
       "4  5.700000e+17  Virgin America   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "                                                                                                                    tokenized  \\\n",
       "0  [what, said]                                                                                                                 \n",
       "1  [plus, youve, added, commercials, to, the, experience, tacky]                                                                \n",
       "2  [i, didnt, today, must, mean, i, need, to, take, another, trip]                                                              \n",
       "3  [its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]   \n",
       "4  [and, its, a, really, big, bad, thing, about, it]                                                                            \n",
       "\n",
       "                                                                                                  clean_text  \\\n",
       "0  what said                                                                                                   \n",
       "1  plus youve added commercials to the experience tacky                                                        \n",
       "2  i didnt today must mean i need to take another trip                                                         \n",
       "3  its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse   \n",
       "4  and its a really big bad thing about it                                                                     \n",
       "\n",
       "    score  \n",
       "0  0.0000  \n",
       "1  0.0000  \n",
       "2  0.0000  \n",
       "3 -0.2716  \n",
       "4 -0.5829  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pred'] = pd.cut(dataset['score'], bins=5, labels=['strongly negative','weakly negative', 'neutral', 'weakly positive','strongly positive' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>[what, said]</td>\n",
       "      <td>what said</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>[plus, youve, added, commercials, to, the, experience, tacky]</td>\n",
       "      <td>plus youve added commercials to the experience tacky</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>[i, didnt, today, must, mean, i, need, to, take, another, trip]</td>\n",
       "      <td>i didnt today must mean i need to take another trip</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>[its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]</td>\n",
       "      <td>its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>weakly negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>[and, its, a, really, big, bad, thing, about, it]</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>-0.5829</td>\n",
       "      <td>strongly negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id         airline  \\\n",
       "0  5.700000e+17  Virgin America   \n",
       "1  5.700000e+17  Virgin America   \n",
       "2  5.700000e+17  Virgin America   \n",
       "3  5.700000e+17  Virgin America   \n",
       "4  5.700000e+17  Virgin America   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "                                                                                                                    tokenized  \\\n",
       "0  [what, said]                                                                                                                 \n",
       "1  [plus, youve, added, commercials, to, the, experience, tacky]                                                                \n",
       "2  [i, didnt, today, must, mean, i, need, to, take, another, trip]                                                              \n",
       "3  [its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]   \n",
       "4  [and, its, a, really, big, bad, thing, about, it]                                                                            \n",
       "\n",
       "                                                                                                  clean_text  \\\n",
       "0  what said                                                                                                   \n",
       "1  plus youve added commercials to the experience tacky                                                        \n",
       "2  i didnt today must mean i need to take another trip                                                         \n",
       "3  its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse   \n",
       "4  and its a really big bad thing about it                                                                     \n",
       "\n",
       "    score               pred  \n",
       "0  0.0000  neutral            \n",
       "1  0.0000  neutral            \n",
       "2  0.0000  neutral            \n",
       "3 -0.2716  weakly negative    \n",
       "4 -0.5829  strongly negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vocab_counter(row):\n",
    "    for word in row:\n",
    "        vocab_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_counter = collections.Counter()\n",
    "tokenized.apply(update_vocab_counter);\n",
    "vocab = sorted(vocab_counter, key=vocab_counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2id = {w:i for i, w in enumerate(vocab[:max_words])}\n",
    "w2id['unk'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ids(row):\n",
    "    return [w2id[w] if w in w2id else w2id['unk'] for w in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokenized_int'] = dataset['tokenized'].apply(lambda x: transform_to_ids(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = dataset['tokenized_int'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 15.984972677595628)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lens), max(lens), np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        'strongly negative': 0,\n",
    "        'weakly negative': 1,\n",
    "        'neutral': 2,\n",
    "        'weakly positive' : 3,\n",
    "        'strongly positive' : 3\n",
    "    }[sentiment]\n",
    "dataset['target'] = dataset.pred.apply(sentiment2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "      <th>tokenized_int</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>[what, said]</td>\n",
       "      <td>what said</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[49, 208]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>[plus, youve, added, commercials, to, the, experience, tacky]</td>\n",
       "      <td>plus youve added commercials to the experience tacky</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[509, 510, 1070, 2304, 0, 1, 188, -1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>[i, didnt, today, must, mean, i, need, to, take, another, trip]</td>\n",
       "      <td>i didnt today must mean i need to take another trip</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[2, 178, 92, 742, 533, 2, 70, 0, 140, 135, 182]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>[its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]</td>\n",
       "      <td>its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>weakly negative</td>\n",
       "      <td>[59, 126, 3390, 0, 4188, 4189, 933, 11, 15, 2879, 3391, 56, 52, 16, 464, 2541]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.700000e+17</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>[and, its, a, really, big, bad, thing, about, it]</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "      <td>-0.5829</td>\n",
       "      <td>strongly negative</td>\n",
       "      <td>[8, 59, 3, 126, 446, 199, 465, 76, 14]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id         airline  \\\n",
       "0  5.700000e+17  Virgin America   \n",
       "1  5.700000e+17  Virgin America   \n",
       "2  5.700000e+17  Virgin America   \n",
       "3  5.700000e+17  Virgin America   \n",
       "4  5.700000e+17  Virgin America   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "                                                                                                                    tokenized  \\\n",
       "0  [what, said]                                                                                                                 \n",
       "1  [plus, youve, added, commercials, to, the, experience, tacky]                                                                \n",
       "2  [i, didnt, today, must, mean, i, need, to, take, another, trip]                                                              \n",
       "3  [its, really, aggressive, to, blast, obnoxious, entertainment, in, your, guests, faces, amp, they, have, little, recourse]   \n",
       "4  [and, its, a, really, big, bad, thing, about, it]                                                                            \n",
       "\n",
       "                                                                                                  clean_text  \\\n",
       "0  what said                                                                                                   \n",
       "1  plus youve added commercials to the experience tacky                                                        \n",
       "2  i didnt today must mean i need to take another trip                                                         \n",
       "3  its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse   \n",
       "4  and its a really big bad thing about it                                                                     \n",
       "\n",
       "    score               pred  \\\n",
       "0  0.0000  neutral             \n",
       "1  0.0000  neutral             \n",
       "2  0.0000  neutral             \n",
       "3 -0.2716  weakly negative     \n",
       "4 -0.5829  strongly negative   \n",
       "\n",
       "                                                                    tokenized_int  \\\n",
       "0  [49, 208]                                                                        \n",
       "1  [509, 510, 1070, 2304, 0, 1, 188, -1]                                            \n",
       "2  [2, 178, 92, 742, 533, 2, 70, 0, 140, 135, 182]                                  \n",
       "3  [59, 126, 3390, 0, 4188, 4189, 933, 11, 15, 2879, 3391, 56, 52, 16, 464, 2541]   \n",
       "4  [8, 59, 3, 126, 446, 199, 465, 76, 14]                                           \n",
       "\n",
       "   target  \n",
       "0  2       \n",
       "1  2       \n",
       "2  2       \n",
       "3  1       \n",
       "4  0       "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,7]\n",
    "y=dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(X_train, maxlen=maxlen, value=-1)\n",
    "x_test = pad_sequences(X_test, maxlen=maxlen, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 514,    6,    1,  224,  171,   84,    1,  754,   -1,  210,   64,\n",
       "           9,  893,    5,   17,    1,  105,   69,   31,   78],\n",
       "       [1760,   42,   11,    8,   42,   47,  112, 1183,    8,  669,   10,\n",
       "          64,    2,  162,  120,   19,    4,   97,   62,    4],\n",
       "       [  -1,   -1,   -1,   -1,   -1,  615,  364,    0,  573,    8,   74,\n",
       "           8,   77,  109,  172,   37,    7,  449, 1744,   28],\n",
       "       [  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "          -1,   -1,   -1,   -1,   -1,   -1,  166,   -1,   -1],\n",
       "       [  73,  116,   12,  261, 3188,   69,   25,    1,  124,    5,    0,\n",
       "          -1,   10,   22,   88,   27,   33,   32,   36,  412]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(len(y_train), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit_and_predict(training_preds, testing_preds):\n",
    "    return np.array_equal(training_preds, testing_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X, y, depth):\n",
    "    clf = DAN2Regressor(depth=depth)\n",
    "    tr_pred = clf.fit(X, y)\n",
    "    path = clf.name\n",
    "    print(clf.coef_)\n",
    "    y_pred = clf.predict(X)\n",
    "    print(tr_pred, y_pred)\n",
    "    print(test_fit_and_predict(tr_pred, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 1.          0.01630493  0.61205353 -0.61950655  1.1288456 ]\n",
      "Iteration: 1  Mu: 1 MSE: 0.9665056257290605 Accuracy: 0.21657559198542806\n",
      "2 [ 3.09017869e+09  7.94059374e-04  1.63336239e+00  2.37768990e-02\n",
      " -2.40995647e-03]\n",
      "Iteration: 2  Mu: 3090178693.4581933 MSE: 0.9663933137865285 Accuracy: 0.21657559198542806\n",
      "3 [ 1.90949952e+09  7.59223125e-03  6.09597766e-01 -1.29965692e+00\n",
      " -6.50873918e+00]\n",
      "Iteration: 3  Mu: 1909499521.4437659 MSE: 0.9657909760072506 Accuracy: 0.21657559198542806\n",
      "4 [1.90983006e+09 3.77772073e-03 1.63718714e+00 7.49474133e-03\n",
      " 8.61576204e-04]\n",
      "Iteration: 4  Mu: 1909830056.2505255 MSE: 0.9657273808918838 Accuracy: 0.21657559198542806\n",
      "5 [ 1.91036487e+09  3.71764290e-03  6.09557413e-01 -1.57414986e+00\n",
      " -2.78628089e+00]\n",
      "Iteration: 5  Mu: 1910364868.1563673 MSE: 0.965654850151888 Accuracy: 0.21657559198542806\n",
      "6 [ 1.90983006e+09 -4.90245784e-05  1.64057648e+00 -3.70262709e-05\n",
      " -7.33693988e-06]\n",
      "Iteration: 6  Mu: 1909830056.2505255 MSE: 0.9656548482426632 Accuracy: 0.21657559198542806\n",
      "7 [ 3.75074812e+09 -1.75892703e-04  6.09736060e-01  7.42298384e+02\n",
      "  1.49261543e+03]\n",
      "Iteration: 7  Mu: 3750748119.4743624 MSE: 0.9652210548436536 Accuracy: 0.21657559198542806\n",
      "8 [ 3.09016994e+09  2.19962209e-03  1.63804070e+00 -9.72537365e-06\n",
      " -4.48979181e-06]\n",
      "Iteration: 8  Mu: 3090169943.7494736 MSE: 0.9651726663492213 Accuracy: 0.21657559198542806\n",
      "9 [ 1.33766302e+09  1.46302551e-03  6.09960774e-01 -5.96120025e+02\n",
      " -1.62045183e+03]\n",
      "Iteration: 9  Mu: 1337663022.9193406 MSE: 0.9651292794065829 Accuracy: 0.21657559198542806\n",
      "10 [ 1.90983053e+09  7.61272560e-04  1.63880954e+00  3.59889777e-05\n",
      " -1.74155690e-06]\n",
      "Iteration: 10  Mu: 1909830527.1283379 MSE: 0.9648957302220615 Accuracy: 0.21657559198542806\n",
      "11 [ 1.90949952e+09 -1.00473453e-03  6.10518534e-01  1.23355714e+01\n",
      "  3.02641504e+02]\n",
      "Iteration: 11  Mu: 1909499521.4437659 MSE: 0.9648955011398993 Accuracy: 0.21657559198542806\n",
      "12 [ 3.09019323e+09  6.25002542e-03  1.63220511e+00  8.54690022e-04\n",
      " -7.83646332e-05]\n",
      "Iteration: 12  Mu: 3090193230.2016497 MSE: 0.9645556115941856 Accuracy: 0.21657559198542806\n",
      "13 [ 1.90949952e+09 -4.40412157e-04  6.12809399e-01  4.23568117e-01\n",
      " -1.62937933e-01]\n",
      "Iteration: 13  Mu: 1909499521.4437659 MSE: 0.9645555467254942 Accuracy: 0.21657559198542806\n",
      "14 [ 1.90983006e+09 -2.91274217e-05  1.63184671e+00 -9.78073890e-05\n",
      " -1.90868890e-03]\n",
      "Iteration: 14  Mu: 1909830056.2505255 MSE: 0.9645554980582285 Accuracy: 0.21657559198542806\n",
      "15 [ 1.90983006e+09  6.66133815e-16  6.12802656e-01 -6.04117974e-14\n",
      "  1.75931102e-14]\n",
      "Iteration: 15  Mu: 1909830056.2505255 MSE: 0.9645554980582285 Accuracy: 0.21657559198542806\n",
      "16 [ 3.78355636e+09 -2.85765655e-03  1.63440892e+00  1.74952333e+11\n",
      "  3.32350387e+11]\n",
      "Iteration: 16  Mu: 3783556356.169721 MSE: 0.9644822868787107 Accuracy: 0.21657559198542806\n",
      "17 [ 3.09016994e+09 -2.48547668e-04  6.11922245e-01  2.14693107e-15\n",
      "  5.36873575e-16]\n",
      "Iteration: 17  Mu: 3090169943.7494736 MSE: 0.964482200460227 Accuracy: 0.21657559198542806\n",
      "18 [ 4.72028868e+09 -1.37330687e-04  1.63419455e+00 -3.03672661e+12\n",
      "  2.10947175e+13]\n",
      "Iteration: 18  Mu: 4720288682.759555 MSE: 0.9643960030591493 Accuracy: 0.21657559198542806\n",
      "19 [ 3.08890365e+09  5.61700352e-03  6.10097637e-01 -4.75216387e-15\n",
      " -5.74313191e-16]\n",
      "Iteration: 19  Mu: 3088903650.071821 MSE: 0.9642180114358415 Accuracy: 0.21657559198542806\n",
      "20 [ 3.10124658e+09 -1.45007614e-04  1.63908191e+00 -1.05441889e+12\n",
      " -2.11472118e+13]\n",
      "Iteration: 20  Mu: 3101246576.31645 MSE: 0.9641314871074627 Accuracy: 0.21657559198542806\n",
      "21 [ 1.90983006e+09  1.33736821e-03  6.09680653e-01 -5.42563549e-16\n",
      " -4.34751106e-18]\n",
      "Iteration: 21  Mu: 1909830056.2505255 MSE: 0.9641312962518387 Accuracy: 0.21657559198542806\n",
      "22 [ 1.19263859e+09  6.73840624e-05  1.64020294e+00 -1.39831557e+13\n",
      " -1.46033516e+09]\n",
      "Iteration: 22  Mu: 1192638586.5686338 MSE: 0.9641024798025003 Accuracy: 0.21657559198542806\n",
      "23 [ 3.81963035e+09  6.35701309e-04  6.09421009e-01 -8.06446714e-16\n",
      " -7.53411263e-13]\n",
      "Iteration: 23  Mu: 3819630352.137556 MSE: 0.9640386877060958 Accuracy: 0.21657559198542806\n",
      "24 [ 1.90983006e+09 -2.48166658e-04  1.64111251e+00 -3.61712270e+11\n",
      " -2.40493016e+08]\n",
      "Iteration: 24  Mu: 1909830056.2505255 MSE: 0.9640386287215457 Accuracy: 0.21657559198542806\n",
      "25 [ 3.96771838e+09  2.54724029e-03  6.08248634e-01 -1.22138799e-13\n",
      "  1.46682878e-11]\n",
      "Iteration: 25  Mu: 3967718378.653796 MSE: 0.9630534695784043 Accuracy: 0.21657559198542806\n",
      "26 [3.09055014e+09 2.71953473e-05 1.64419003e+00 9.52252319e+10\n",
      " 1.13532172e+08]\n",
      "Iteration: 26  Mu: 3090550137.1987777 MSE: 0.9629847561112517 Accuracy: 0.21657559198542806\n",
      "27 [ 1.91029967e+09  3.65081809e-04  6.07929261e-01 -2.04036016e-13\n",
      " -3.74191191e-11]\n",
      "Iteration: 27  Mu: 1910299671.9230042 MSE: 0.9627889560261446 Accuracy: 0.21657559198542806\n",
      "28 [ 1.90983006e+09 -1.54340664e-04  1.64507225e+00 -1.55298199e+09\n",
      "  1.17508959e+07]\n",
      "Iteration: 28  Mu: 1909830056.2505255 MSE: 0.9627888106766058 Accuracy: 0.21657559198542806\n",
      "29 [ 3.82230524e+09  2.67496916e-04  6.07725051e-01 -6.53995276e-12\n",
      "  2.04412059e-09]\n",
      "Iteration: 29  Mu: 3822305243.5980444 MSE: 0.9624519409346183 Accuracy: 0.21657559198542806\n",
      "30 [ 3.09016994e+09  3.27817860e-05  1.64543797e+00 -7.68622013e+07\n",
      " -5.60353271e+05]\n",
      "Iteration: 30  Mu: 3090169943.7494736 MSE: 0.9624511635365248 Accuracy: 0.21657559198542806\n",
      "31 [ 3.81602899e+09  2.41533456e-03  6.06955455e-01 -1.30301509e-10\n",
      " -2.23808662e-08]\n",
      "Iteration: 31  Mu: 3816028990.662137 MSE: 0.9623236921601741 Accuracy: 0.21657559198542806\n",
      "32 [ 1.90983006e+09 -2.73760712e-04  1.64780554e+00 -3.00577918e+06\n",
      " -4.23972281e+02]\n",
      "Iteration: 32  Mu: 1909830056.2505255 MSE: 0.9623236153659612 Accuracy: 0.21657559198542806\n",
      "33 [ 3.81966039e+09  1.61743774e-03  6.06289378e-01 -6.25139555e-09\n",
      " -1.90549530e-05]\n",
      "Iteration: 33  Mu: 3819660385.8987446 MSE: 0.9621133755749524 Accuracy: 0.21657559198542806\n",
      "34 [ 1.90983006e+09 -5.92924163e-05  1.64943354e+00 -2.12708046e+04\n",
      "  1.01790144e+01]\n",
      "Iteration: 34  Mu: 1909830056.2505255 MSE: 0.9621133482121016 Accuracy: 0.21657559198542806\n",
      "35 [ 3.81971747e+09  6.95345548e-03  6.03894213e-01 -1.67800521e-06\n",
      " -5.82935941e-04]\n",
      "Iteration: 35  Mu: 3819717473.3614283 MSE: 0.9614566806097551 Accuracy: 0.21657559198542806\n",
      "36 [ 1.90983006e+09 -6.75053058e-04  1.65650708e+00 -5.62441657e+02\n",
      " -2.21913375e-01]\n",
      "Iteration: 36  Mu: 1909830056.2505255 MSE: 0.9614562263677746 Accuracy: 0.21657559198542806\n",
      "37 [ 3.82737218e+09 -3.03694033e-03  6.04671640e-01  1.43451330e-05\n",
      "  3.49197762e-02]\n",
      "Iteration: 37  Mu: 3827372184.0945024 MSE: 0.9613933044083178 Accuracy: 0.21657559198542806\n",
      "38 [ 3.09016994e+09  1.70807403e-04  1.65364767e+00 -4.98347880e+01\n",
      "  1.34850694e-02]\n",
      "Iteration: 38  Mu: 3090169943.7494736 MSE: 0.961392936070717 Accuracy: 0.21657559198542806\n",
      "39 [ 3.82337419e+09  2.51436694e-04  6.04647259e-01 -1.25973976e-04\n",
      " -1.07195496e+00]\n",
      "Iteration: 39  Mu: 3823374189.0877275 MSE: 0.9612676251468502 Accuracy: 0.21657559198542806\n",
      "40 [ 1.90983006e+09  2.90828491e-04  1.65359996e+00  3.78305668e+00\n",
      " -8.38795504e-05]\n",
      "Iteration: 40  Mu: 1909830056.2505255 MSE: 0.9612675075995527 Accuracy: 0.21657559198542806\n",
      "41 [ 1.90949952e+09  3.30216999e-04  6.04634504e-01 -2.00600758e-04\n",
      "  7.72620167e+00]\n",
      "Iteration: 41  Mu: 1909499521.4437659 MSE: 0.9612670088125959 Accuracy: 0.21657559198542806\n",
      "42 [ 3.09016994e+09  3.55550616e-05  1.65385837e+00 -2.01224818e-01\n",
      " -2.66626032e-05]\n",
      "Iteration: 42  Mu: 3090169943.7494736 MSE: 0.9612669870080996 Accuracy: 0.21657559198542806\n",
      "43 [ 3.76633458e+09 -2.05938933e-04  6.04697654e-01 -1.16632107e-02\n",
      "  5.11889457e+02]\n",
      "Iteration: 43  Mu: 3766334582.8156037 MSE: 0.961172214329865 Accuracy: 0.21657559198542806\n",
      "44 [ 3.09023388e+09  2.38110856e-03  1.65105243e+00 -1.81526475e+00\n",
      " -3.83673257e-05]\n",
      "Iteration: 44  Mu: 3090233875.6317782 MSE: 0.9607466610610006 Accuracy: 0.21657559198542806\n",
      "45 [ 3.75397458e+09  1.04911519e-03  6.05311748e-01 -3.57762016e-03\n",
      " -1.99691118e+00]\n",
      "Iteration: 45  Mu: 3753974578.7524347 MSE: 0.9607256247973964 Accuracy: 0.21657559198542806\n",
      "46 [ 1.90983006e+09 -1.39585745e-04  1.65217236e+00 -8.47583138e-02\n",
      "  1.98658478e-04]\n",
      "Iteration: 46  Mu: 1909830056.2505255 MSE: 0.9607255013848891 Accuracy: 0.21657559198542806\n",
      "47 [ 3.81983754e+09 -2.65931464e-03  6.06137801e-01  1.76577541e-01\n",
      " -6.10027863e+01]\n",
      "Iteration: 47  Mu: 3819837536.9439793 MSE: 0.9605401140691412 Accuracy: 0.21657559198542806\n",
      "48 [ 1.90983006e+09  1.92769461e-04  1.64961924e+00 -1.86219200e-03\n",
      " -1.47012900e-06]\n",
      "Iteration: 48  Mu: 1909830056.2505255 MSE: 0.9605400560654481 Accuracy: 0.21657559198542806\n",
      "49 [ 3.83219992e+09  2.41332413e-03  6.05591678e-01  9.33046639e+00\n",
      " -1.73040047e+04]\n",
      "Iteration: 49  Mu: 3832199923.5229664 MSE: 0.9600699489063007 Accuracy: 0.21657559198542806\n",
      "50 [ 1.90983006e+09  1.09152096e-04  1.65118155e+00 -1.93527055e-05\n",
      " -1.38156626e-09]\n",
      "Iteration: 50  Mu: 1909830056.2505255 MSE: 0.9600699323143186 Accuracy: 0.21657559198542806\n",
      "[[ 1.00000000e+00  1.63049269e-02  6.12053532e-01 -6.19506546e-01\n",
      "   1.12884560e+00]\n",
      " [ 3.09017869e+09  7.94059374e-04  1.63336239e+00  2.37768990e-02\n",
      "  -2.40995647e-03]\n",
      " [ 1.90949952e+09  7.59223125e-03  6.09597766e-01 -1.29965692e+00\n",
      "  -6.50873918e+00]\n",
      " [ 1.90983006e+09  3.77772073e-03  1.63718714e+00  7.49474133e-03\n",
      "   8.61576204e-04]\n",
      " [ 1.91036487e+09  3.71764290e-03  6.09557413e-01 -1.57414986e+00\n",
      "  -2.78628089e+00]\n",
      " [ 1.90983006e+09 -4.90245784e-05  1.64057648e+00 -3.70262709e-05\n",
      "  -7.33693988e-06]\n",
      " [ 3.75074812e+09 -1.75892703e-04  6.09736060e-01  7.42298384e+02\n",
      "   1.49261543e+03]\n",
      " [ 3.09016994e+09  2.19962209e-03  1.63804070e+00 -9.72537365e-06\n",
      "  -4.48979181e-06]\n",
      " [ 1.33766302e+09  1.46302551e-03  6.09960774e-01 -5.96120025e+02\n",
      "  -1.62045183e+03]\n",
      " [ 1.90983053e+09  7.61272560e-04  1.63880954e+00  3.59889777e-05\n",
      "  -1.74155690e-06]\n",
      " [ 1.90949952e+09 -1.00473453e-03  6.10518534e-01  1.23355714e+01\n",
      "   3.02641504e+02]\n",
      " [ 3.09019323e+09  6.25002542e-03  1.63220511e+00  8.54690022e-04\n",
      "  -7.83646332e-05]\n",
      " [ 1.90949952e+09 -4.40412157e-04  6.12809399e-01  4.23568117e-01\n",
      "  -1.62937933e-01]\n",
      " [ 1.90983006e+09 -2.91274217e-05  1.63184671e+00 -9.78073890e-05\n",
      "  -1.90868890e-03]\n",
      " [ 1.90983006e+09  6.66133815e-16  6.12802656e-01 -6.04117974e-14\n",
      "   1.75931102e-14]\n",
      " [ 3.78355636e+09 -2.85765655e-03  1.63440892e+00  1.74952333e+11\n",
      "   3.32350387e+11]\n",
      " [ 3.09016994e+09 -2.48547668e-04  6.11922245e-01  2.14693107e-15\n",
      "   5.36873575e-16]\n",
      " [ 4.72028868e+09 -1.37330687e-04  1.63419455e+00 -3.03672661e+12\n",
      "   2.10947175e+13]\n",
      " [ 3.08890365e+09  5.61700352e-03  6.10097637e-01 -4.75216387e-15\n",
      "  -5.74313191e-16]\n",
      " [ 3.10124658e+09 -1.45007614e-04  1.63908191e+00 -1.05441889e+12\n",
      "  -2.11472118e+13]\n",
      " [ 1.90983006e+09  1.33736821e-03  6.09680653e-01 -5.42563549e-16\n",
      "  -4.34751106e-18]\n",
      " [ 1.19263859e+09  6.73840624e-05  1.64020294e+00 -1.39831557e+13\n",
      "  -1.46033516e+09]\n",
      " [ 3.81963035e+09  6.35701309e-04  6.09421009e-01 -8.06446714e-16\n",
      "  -7.53411263e-13]\n",
      " [ 1.90983006e+09 -2.48166658e-04  1.64111251e+00 -3.61712270e+11\n",
      "  -2.40493016e+08]\n",
      " [ 3.96771838e+09  2.54724029e-03  6.08248634e-01 -1.22138799e-13\n",
      "   1.46682878e-11]\n",
      " [ 3.09055014e+09  2.71953473e-05  1.64419003e+00  9.52252319e+10\n",
      "   1.13532172e+08]\n",
      " [ 1.91029967e+09  3.65081809e-04  6.07929261e-01 -2.04036016e-13\n",
      "  -3.74191191e-11]\n",
      " [ 1.90983006e+09 -1.54340664e-04  1.64507225e+00 -1.55298199e+09\n",
      "   1.17508959e+07]\n",
      " [ 3.82230524e+09  2.67496916e-04  6.07725051e-01 -6.53995276e-12\n",
      "   2.04412059e-09]\n",
      " [ 3.09016994e+09  3.27817860e-05  1.64543797e+00 -7.68622013e+07\n",
      "  -5.60353271e+05]\n",
      " [ 3.81602899e+09  2.41533456e-03  6.06955455e-01 -1.30301509e-10\n",
      "  -2.23808662e-08]\n",
      " [ 1.90983006e+09 -2.73760712e-04  1.64780554e+00 -3.00577918e+06\n",
      "  -4.23972281e+02]\n",
      " [ 3.81966039e+09  1.61743774e-03  6.06289378e-01 -6.25139555e-09\n",
      "  -1.90549530e-05]\n",
      " [ 1.90983006e+09 -5.92924163e-05  1.64943354e+00 -2.12708046e+04\n",
      "   1.01790144e+01]\n",
      " [ 3.81971747e+09  6.95345548e-03  6.03894213e-01 -1.67800521e-06\n",
      "  -5.82935941e-04]\n",
      " [ 1.90983006e+09 -6.75053058e-04  1.65650708e+00 -5.62441657e+02\n",
      "  -2.21913375e-01]\n",
      " [ 3.82737218e+09 -3.03694033e-03  6.04671640e-01  1.43451330e-05\n",
      "   3.49197762e-02]\n",
      " [ 3.09016994e+09  1.70807403e-04  1.65364767e+00 -4.98347880e+01\n",
      "   1.34850694e-02]\n",
      " [ 3.82337419e+09  2.51436694e-04  6.04647259e-01 -1.25973976e-04\n",
      "  -1.07195496e+00]\n",
      " [ 1.90983006e+09  2.90828491e-04  1.65359996e+00  3.78305668e+00\n",
      "  -8.38795504e-05]\n",
      " [ 1.90949952e+09  3.30216999e-04  6.04634504e-01 -2.00600758e-04\n",
      "   7.72620167e+00]\n",
      " [ 3.09016994e+09  3.55550616e-05  1.65385837e+00 -2.01224818e-01\n",
      "  -2.66626032e-05]\n",
      " [ 3.76633458e+09 -2.05938933e-04  6.04697654e-01 -1.16632107e-02\n",
      "   5.11889457e+02]\n",
      " [ 3.09023388e+09  2.38110856e-03  1.65105243e+00 -1.81526475e+00\n",
      "  -3.83673257e-05]\n",
      " [ 3.75397458e+09  1.04911519e-03  6.05311748e-01 -3.57762016e-03\n",
      "  -1.99691118e+00]\n",
      " [ 1.90983006e+09 -1.39585745e-04  1.65217236e+00 -8.47583138e-02\n",
      "   1.98658478e-04]\n",
      " [ 3.81983754e+09 -2.65931464e-03  6.06137801e-01  1.76577541e-01\n",
      "  -6.10027863e+01]\n",
      " [ 1.90983006e+09  1.92769461e-04  1.64961924e+00 -1.86219200e-03\n",
      "  -1.47012900e-06]\n",
      " [ 3.83219992e+09  2.41332413e-03  6.05591678e-01  9.33046639e+00\n",
      "  -1.73040047e+04]\n",
      " [ 1.90983006e+09  1.09152096e-04  1.65118155e+00 -1.93527055e-05\n",
      "  -1.38156626e-09]]\n",
      "[[2.05820163]\n",
      " [1.87413846]\n",
      " [2.04556491]\n",
      " ...\n",
      " [2.09524547]\n",
      " [2.01263481]\n",
      " [1.85453137]] [[2.05820163]\n",
      " [1.87413846]\n",
      " [2.04556491]\n",
      " ...\n",
      " [2.09524547]\n",
      " [2.01263481]\n",
      " [1.85453137]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(x_train,y_train, depth=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
